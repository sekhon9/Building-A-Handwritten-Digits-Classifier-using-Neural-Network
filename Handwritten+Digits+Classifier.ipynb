{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "In this project we will be doing the following:\n",
    "*  explore why image classification is a hard task\n",
    "*  observe the limitations of traditional machine learning models for image classification\n",
    "*  train, test, and improve a few different deep neural networks for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep neural networks have been used to reach state-of-the-art performance on image classification tasks in the last decade. For some image classification tasks, deep neural networks actually perform as well as or slightly better than the human benchmark. \n",
    "\n",
    "Before the year 2000, institutions like the United States Post Office used handwriting recognition software to read addresses, zip codes, and more. One of their approaches, which consists of pre-processing handwritten images then feeding to a neural network model is detailed in this paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Why is image classifcation a hard task?\n",
    "\n",
    "Within the field of machine learning and pattern recognition, image classification (especially for handwritten text) is towards the difficult end of the spectrum. There are a few reasons for this.\n",
    "\n",
    "First, each image in a training set is high dimensional. Each pixel in an image is a feature and a separate column. This means that a 128 x 128 image has 16384 features.\n",
    "\n",
    "Second, images are often downsampled to lower resolutions and transformed to grayscale (no color). This is a limitation of compute power unfortunately. The resolution of a 8 megapixel photo has 3264 by 2448 pixels, for a total of 7,990,272 features (or about 8 million). Images of this resolution are usually scaled down to between 128 and 512 pixels in either direction for significantly faster processing. This often results in a loss of detail that's available for training and pattern matching.\n",
    "\n",
    "Third, the features in an image don't have an obvious linear or nonlinear relationship that can be learned with a model like linear or logistic regression. In grayscale, each pixel is just represented as a brightness value ranging from 0 to 256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Why is deep learning effective in image classification?\n",
    "\n",
    "Deep learning is effective in image classification because of the models' ability to learn hierarchical representations. At a high level, an effective deep learning model learns intermediate representations at each layer in the model and uses them in the prediction process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Working With Image Data\n",
    "Since dataframes are a tabular representation of data, each image is represented as a row of pixel values. To visualize an image from the dataframe, we need to reshape the image back to its original dimensions (28 x 28 pixels). To visualize the image, we need to reshape these pixel values back into the 28 by 28 and plot them on a coordinate grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "digits_data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking out the keys to identify the labels\n",
    "digits_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isolating the labels in a series\n",
    "labels = pd.Series(digits_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using the data key to create a dataframe\n",
    "data = pd.DataFrame(digits_data['data'])\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Isolating the first image and reshaping the matrix for plotting\n",
    "first_image = data.iloc[0]\n",
    "np_image = first_image.values\n",
    "np_image = np_image.reshape(8, 8)\n",
    "\n",
    "plt.imshow(np_image, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And a few more...\n",
    "f, axarr = plt.subplots(2, 4)\n",
    "\n",
    "axarr[0, 0].imshow(data.iloc[0].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 1].imshow(data.iloc[99].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 2].imshow(data.iloc[199].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[0, 3].imshow(data.iloc[299].values.reshape(8,8), cmap='gray_r')\n",
    "\n",
    "axarr[1, 0].imshow(data.iloc[999].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 1].imshow(data.iloc[1099].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 2].imshow(data.iloc[1199].values.reshape(8,8), cmap='gray_r')\n",
    "axarr[1, 3].imshow(data.iloc[1299].values.reshape(8,8), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### K-Nearest Neighbors Model\n",
    "While linear and logistic regression models make assumptions about the linearity between the features and the output labels, the k-nearest neighbors algorithm make no such assumption. This allows them to capture nonlinearity in the data. If we recall, k-nearest neighbors don't have a specific model representation (hence why it's referred to as an algorithm and not a model).\n",
    "\n",
    "The k-nearest neighbors algorithm compares every unseen observation in the test set to all (or many, as some implementations constrain the search space) training observations to look for similar (or the \"nearest\") observations. Then, the algorithm finds the label with the most nearby observations and assigns that as the prediction for the unseen observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Defining a function that will complete the training of the models\n",
    "def train_knn(nneighbors, train_features, train_labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors = nneighbors)\n",
    "    knn.fit(train_features, train_labels)\n",
    "    return knn\n",
    "\n",
    "# Defining a function that will test the created models\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "# Defining a function that will perform 4-fold cross validation using train() and test()\n",
    "def cross_validate(k):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "        model = train_knn(k, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies\n",
    "\n",
    "knn_one_accuracies = cross_validate(1)\n",
    "np.mean(knn_one_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the accuracies\n",
    "k_values = list(range(1,10))\n",
    "k_overall_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    k_accuracies = cross_validate(k)\n",
    "    k_mean_accuracy = np.mean(k_accuracies)\n",
    "    k_overall_accuracies.append(k_mean_accuracy)\n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. k\")\n",
    "plt.plot(k_values, k_overall_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Neural Network With One Hidden Layer\n",
    "From the last step we see thats there are a few downsides to using k-nearest neighbors:\n",
    "\n",
    "*  high memory usage (for each new unseen observation, many comparisons need to be made to seen observations)\n",
    "*  no model representation to debug and explore\n",
    "\n",
    "Let's now try a neural network with a single hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 50% Train / test validation\n",
    "def train_nn(neuron_arch, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_arch)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate(neuron_arch):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 4, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "       \n",
    "        model = train_nn(neuron_arch, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_one_neurons = [\n",
    "    (8,),\n",
    "    (16,),\n",
    "    (32,),\n",
    "    (64,),\n",
    "    (128,),\n",
    "    (256,)\n",
    "]\n",
    "nn_one_accuracies = []\n",
    "\n",
    "for n in nn_one_neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_one_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Single Hidden Layer\")\n",
    "\n",
    "x = [i[0] for i in nn_one_neurons]\n",
    "plt.plot(x, nn_one_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_one_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The best accuracy (~95%) can be seen when there are 128 neurons in the hidden layer. In general the performance is better where there are more neuronsâ€“at least for this set. Because KNN gave us an accuracy around 96%, the use of a neural network doesn't seem to give us a real reason to switch. At least not with a single hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Neural Network with Two Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_two_neurons = [\n",
    "    (64,64),\n",
    "    (128, 128),\n",
    "    (256, 256)\n",
    "]\n",
    "nn_two_accuracies = []\n",
    "\n",
    "for n in nn_two_neurons:\n",
    "    nn_accuracies = cross_validate(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_two_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Two Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in nn_two_neurons]\n",
    "plt.plot(x, nn_two_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_two_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the performance of this model improves as a whole compared to the single layer neural network. The highest accuracy in this modelonly very slightly exceeds that of the single layer model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Neural Network with Three Hidden Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 50% Train / test validation\n",
    "def train_nn(neuron_arch, train_features, train_labels):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neuron_arch)\n",
    "    mlp.fit(train_features, train_labels)\n",
    "    return mlp\n",
    "\n",
    "def test(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    train_test_df = pd.DataFrame()\n",
    "    train_test_df['correct_label'] = test_labels\n",
    "    train_test_df['predicted_label'] = predictions\n",
    "    overall_accuracy = sum(train_test_df[\"predicted_label\"] == train_test_df[\"correct_label\"])/len(train_test_df)    \n",
    "    return overall_accuracy\n",
    "\n",
    "def cross_validate_six(neuron_arch):\n",
    "    fold_accuracies = []\n",
    "    kf = KFold(n_splits = 6, random_state=2)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_features, test_features = data.loc[train_index], data.loc[test_index]\n",
    "        train_labels, test_labels = labels.loc[train_index], labels.loc[test_index]\n",
    "       \n",
    "        model = train_nn(neuron_arch, train_features, train_labels)\n",
    "        overall_accuracy = test(model, test_features, test_labels)\n",
    "        fold_accuracies.append(overall_accuracy)\n",
    "    return fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_three_neurons = [\n",
    "    (10, 10, 10),\n",
    "    (64, 64, 64),\n",
    "    (128, 128, 128)\n",
    "]\n",
    "\n",
    "nn_three_accuracies = []\n",
    "\n",
    "for n in nn_three_neurons:\n",
    "    nn_accuracies = cross_validate_six(n)\n",
    "    nn_mean_accuracy = np.mean(nn_accuracies)\n",
    "    nn_three_accuracies.append(nn_mean_accuracy)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Mean Accuracy vs. Neurons In Three Hidden Layers\")\n",
    "\n",
    "x = [i[0] for i in nn_three_neurons]\n",
    "plt.plot(x, nn_three_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_three_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With three hidden layers, we see a small improvement in the highest accuracy. However, the increase in accuracy is pretty small. If we wanted to see a better outcome or even one with a lower chance of overfitting we'd need to invesitage further and possibly adjust the k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
